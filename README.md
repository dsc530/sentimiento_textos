# üß† An√°lisis de Sentimientos de Opiniones de Productos

Este proyecto realiza un an√°lisis de sentimientos sobre opiniones de productos, entrenando y comparando distintos enfoques de procesamiento de texto y clasificaci√≥n.

---

## üéØ Objetivos

- **Preprocesar** las opiniones normalizando y limpiando el texto.  
- **Extraer caracter√≠sticas** mediante TF-IDF y embeddings BERT.  
- **Entrenar** modelos de clasificaci√≥n para predecir la polaridad (`Positiva` / `Negativa`).  
- **Evaluar** el rendimiento de cada modelo frente a un modelo base (*dummy*).

---

## üîç Flujo de Trabajo

1. ### Importaci√≥n y Preparaci√≥n  
   - Carga de librer√≠as y recursos de NLTK y spaCy.  
   - Lectura del CSV con las opiniones y sus etiquetas.  

2. ### Preprocesamiento de Texto  
   - Min√∫sculas, eliminaci√≥n de puntuaci√≥n y espacios extras.  
   - Lemmatizaci√≥n con NLTK y con spaCy.  

3. ### Extracci√≥n de Caracter√≠sticas  
   - **TF-IDF** sobre tokens de NLTK y de spaCy.  
   - **Embeddings** con un modelo BERT preentrenado.  

4. ### Divisi√≥n de Datos  
   - Separaci√≥n en entrenamiento y prueba (80 %/20 %).  

5. ### Entrenamiento de Modelos  
   - **Regresi√≥n Log√≠stica** (TF-IDF NLTK y TF-IDF spaCy)  
   - **LightGBM** (TF-IDF)  
   - **Modelo Dummy** como referencia.  

6. ### Evaluaci√≥n  
   - C√°lculo de **accuracy**, **F1-score** y comparaci√≥n frente al modelo dummy.

---

## üìä Conclusiones Principales

### An√°lisis Exploratorio de Datos  
- La cantidad de rese√±as por pel√≠cula tiende a aumentar con el tiempo.  
- La mayor√≠a de las pel√≠culas acumula **1‚Äì3 rese√±as**, aunque existen ~400 pel√≠culas con **30 comentarios**.  
- La proporci√≥n de rese√±as negativas y positivas est√° bien balanceada en entrenamiento y prueba.  
- Muchas pel√≠culas tienen **1‚Äì2 rese√±as negativas**, mientras que las rese√±as positivas est√°n m√°s distribuidas.

### Comparaci√≥n de Lemmatizaci√≥n (NLTK vs spaCy)  
- Ambos m√©todos arrojan m√©tricas casi id√©nticas con Regresi√≥n Log√≠stica sobre TF-IDF.  
- El vectorizador TF-IDF es el mismo en todos los casos, por lo que no introduce variaci√≥n.

### Rendimiento de Modelos  
- **Regresi√≥n Log√≠stica** y **LightGBM** obtuvieron F1 en entrenamiento entre **0.91‚Äì0.94** y en prueba entre **0.86‚Äì0.88**.  
- Todos superaron ampliamente al modelo **dummy**.  

### Modelos con Datos Manuales  
- Al clasificar manualmente comentarios como positivos o negativos:
  - **LightGBM** fue el mejor modelo de predicci√≥n.  
  - La **Regresi√≥n Log√≠stica con spaCy** fue el de peor resultado.  
  - Los F1 finales son muy similares a los obtenidos en conjunto de prueba (~0.88).

---

## ## üß∞ Requisitos del Entorno

- Python 3.8 o superior  
- pandas  
- numpy  
- scikit-learn  
- matplotlib  
- seaborn  
- nltk  
- spacy  
- transformers  


